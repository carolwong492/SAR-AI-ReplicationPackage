{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNPMoCpIKe9EzBOEkiI6UMh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J0fKPqtXz8p4","executionInfo":{"status":"ok","timestamp":1764926637203,"user_tz":600,"elapsed":8573,"user":{"displayName":"Kye Steele","userId":"15448004020711484831"}},"outputId":"957f1742-f537-41d2-c55b-c1dd29753562"},"outputs":[{"output_type":"stream","name":"stdout","text":["starting script.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["finished querying parquets.\n","2288\n","length of combined_df: 2288\n","building regex.\n","searching sar patterns.\n","----- sar pattern location summary -----\n","title only:  13\n","body only:   274\n","both:        30\n","neither:     1971\n","----------------------------------------\n","\n","----- fisher exact test (title vs body) -----\n","2x2 table: [[30, 13], [274, 1971]]\n","odds ratio: 16.600224592925322\n","p-value: 9.989071974289105e-18\n","---------------------------------------------\n"]}],"source":["import pandas as pd\n","import re\n","from scipy.stats import fisher_exact\n","from scipy.stats.contingency import odds_ratio\n","from bug_fix_list import bug_words\n","from internal_list import internal_words\n","from external_list import external_words\n","from functional_list import functional_words\n","from code_smell_list import smell_words\n","\n","print('starting script.')\n","pd.set_option('display.max_rows', None)\n","\n","pull_request_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pull_request.parquet\")\n","comments_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pr_comments.parquet\")\n","pr_task_type_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pr_task_type.parquet\")\n","print('finished querying parquets.')\n","\n","pull_request_df.rename(columns={'id': 'pr_id'}, inplace=True)\n","\n","# need comment bodies\n","combined_df = pull_request_df.merge(\n","    comments_df[['id', 'body']].add_prefix('comment_'),\n","    how='left',\n","    left_on='pr_id',\n","    right_on='comment_id'\n",")\n","\n","# only keep refactor prs\n","combined_df = combined_df.merge(\n","    pr_task_type_df[['id', 'type']],\n","    how='left',\n","    left_on='pr_id',\n","    right_on='id'\n",")\n","combined_df.rename(columns={'type': 'pr_type'}, inplace=True)\n","combined_df = combined_df.loc[combined_df['pr_type'].str.contains('refactor', na=False)].copy()\n","\n","print(combined_df['pr_id'].nunique())\n","print(f\"length of combined_df: {len(combined_df)}\")\n","\n","print('building regex.')\n","\n","def to_regex_pattern(word):\n","    return re.escape(word).replace(r'\\*', '.*')\n","\n","all_patterns = re.compile(\n","    '|'.join(to_regex_pattern(w) for w in (\n","        bug_words + internal_words + external_words + functional_words + smell_words\n","    )),\n","    re.IGNORECASE\n",")\n","\n","print('searching sar patterns.')\n","\n","# check title/body for sar\n","combined_df['sar_in_pr_title'] = combined_df['title'].str.contains(all_patterns, na=False)\n","combined_df['sar_in_pr_body'] = combined_df['body'].str.contains(all_patterns, na=False)\n","\n","# drop dupes so 1 row per pr\n","unique_prs = combined_df.drop_duplicates(subset=['pr_id'])\n","\n","# count combos\n","title_only = unique_prs[(unique_prs['sar_in_pr_title']) & (~unique_prs['sar_in_pr_body'])]\n","body_only = unique_prs[(unique_prs['sar_in_pr_body']) & (~unique_prs['sar_in_pr_title'])]\n","both = unique_prs[(unique_prs['sar_in_pr_title']) & (unique_prs['sar_in_pr_body'])]\n","neither = unique_prs[(~unique_prs['sar_in_pr_title']) & (~unique_prs['sar_in_pr_body'])]\n","\n","print(\"----- sar pattern location summary -----\")\n","print(f\"title only:  {len(title_only)}\")\n","print(f\"body only:   {len(body_only)}\")\n","print(f\"both:        {len(both)}\")\n","print(f\"neither:     {len(neither)}\")\n","print(\"----------------------------------------\")\n","\n","# statistical analysis with fisher's exact test\n","table = [\n","    [len(both), len(title_only)],\n","    [len(body_only), len(neither)]\n","]\n","\n","odds_ratio, p_value = fisher_exact(table)\n","\n","print(\"\\n----- fisher exact test (title vs body) -----\")\n","print(f\"2x2 table: {table}\")\n","print(f\"odds ratio: {odds_ratio}\")\n","print(f\"p-value: {p_value}\")\n","print(\"---------------------------------------------\")"]}]}