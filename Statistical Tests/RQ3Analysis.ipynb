{"cells":[{"cell_type":"code","execution_count":1,"id":"e5ae3930-b8d2-472e-af8e-71db90a82533","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4867,"status":"ok","timestamp":1764807364342,"user":{"displayName":"Carol Wong","userId":"15667668278021680660"},"user_tz":600},"id":"e5ae3930-b8d2-472e-af8e-71db90a82533","outputId":"1a9c7df3-8564-44e7-ba90-c1b4bbb2e67f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import pandas as pd\n","import re\n","import statsmodels.api as sm\n","from statsmodels.formula.api import ols\n","import numpy as np\n","\n","from scipy import stats\n","from scipy.stats import f_oneway, mannwhitneyu, kruskal\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","directory = '/content/drive/Shared drives/ICS 691G Research Project/Research Project/Data Analysis'\n","sys.path.append(directory)\n","\n","import bug_fix_list\n","import internal_list\n","import external_list\n","import functional_list\n","import code_smell_list\n","\n","bug_words = bug_fix_list.bug_words\n","internal_words = internal_list.internal_words\n","external_words = external_list.external_words\n","functional_words = functional_list.functional_words\n","smell_words = code_smell_list.smell_words\n"]},{"cell_type":"code","execution_count":4,"id":"a90b193f-d78a-4770-a923-64823b0617f3","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":650},"executionInfo":{"elapsed":240,"status":"error","timestamp":1764809058489,"user":{"displayName":"Carol Wong","userId":"15667668278021680660"},"user_tz":600},"id":"a90b193f-d78a-4770-a923-64823b0617f3","outputId":"98976086-c65e-4c2b-a24c-26c477ddddfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting script.\n"]},{"output_type":"error","ename":"HfHubHTTPError","evalue":"429 Client Error: Too Many Requests for url: https://us.gcp.cdn.hf.co/xet-bridge-us/688396b205d1d6f23ea2db87/a2ee09c5cdb6feaa352311ab9e29183c7db352bf6b02539c8b36b2f63fef62f2?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pull_request.parquet%3B+filename%3D%22pull_request.parquet%22%3B&Expires=1764812658&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY0ODEyNjU4fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjg4Mzk2YjIwNWQxZDZmMjNlYTJkYjg3L2EyZWUwOWM1Y2RiNmZlYWEzNTIzMTFhYjllMjkxODNjN2RiMzUyYmY2YjAyNTM5YzhiMzZiMmY2M2ZlZjYyZjJcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=t3Ot17q9UhNsFr-KKdepa~eoNzo7HFwc0I1sWPLZuMPj2WVw4mExEhnmUf9YH~ZuZ4q3GtTfbI7riy7Db~VRKvu4sN9cAQf4cWCO6B9Xpg3xiiKxsllstM9fJ3yHGtHOmwsPIsOIU0LibBQkF0yWUkkaVyg1rbR8ouQHK~xXWAWLApw2LjYvU6mutcSRfkedomyec8xakIn3pyraiTsgABFOotMkUKGhr~zVZJReUG0y3OIC6b3iFGl4GfN4D9vpsctpO-69wx4TddgSQ74JW0I76CtOw~vlyD9UZlr43nLNNP49jgVhFfWctNQX7pmGvsHMgz6mrP7N-ctbaNKeyg__&Key-Pair-Id=KJLH8B0YWU4Y8M","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://us.gcp.cdn.hf.co/xet-bridge-us/688396b205d1d6f23ea2db87/a2ee09c5cdb6feaa352311ab9e29183c7db352bf6b02539c8b36b2f63fef62f2?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pull_request.parquet%3B+filename%3D%22pull_request.parquet%22%3B&Expires=1764812658&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY0ODEyNjU4fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjg4Mzk2YjIwNWQxZDZmMjNlYTJkYjg3L2EyZWUwOWM1Y2RiNmZlYWEzNTIzMTFhYjllMjkxODNjN2RiMzUyYmY2YjAyNTM5YzhiMzZiMmY2M2ZlZjYyZjJcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=t3Ot17q9UhNsFr-KKdepa~eoNzo7HFwc0I1sWPLZuMPj2WVw4mExEhnmUf9YH~ZuZ4q3GtTfbI7riy7Db~VRKvu4sN9cAQf4cWCO6B9Xpg3xiiKxsllstM9fJ3yHGtHOmwsPIsOIU0LibBQkF0yWUkkaVyg1rbR8ouQHK~xXWAWLApw2LjYvU6mutcSRfkedomyec8xakIn3pyraiTsgABFOotMkUKGhr~zVZJReUG0y3OIC6b3iFGl4GfN4D9vpsctpO-69wx4TddgSQ74JW0I76CtOw~vlyD9UZlr43nLNNP49jgVhFfWctNQX7pmGvsHMgz6mrP7N-ctbaNKeyg__&Key-Pair-Id=KJLH8B0YWU4Y8M","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3506901489.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting script.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_rows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpull_request_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hf://datasets/hao-li/AIDev/pull_request.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mcomments_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hf://datasets/hao-li/AIDev/pr_comments.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpr_task_type_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hf://datasets/hao-li/AIDev/pr_task_type.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0mcheck_dtype_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m         )\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             pa_table = self.api.parquet.read_table(\n\u001b[0m\u001b[1;32m    275\u001b[0m                 \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[0m\n\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m         dataset = ParquetDataset(\n\u001b[0m\u001b[1;32m   1794\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m             \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_paths, filesystem, schema, filters, read_dictionary, memory_map, buffer_size, partitioning, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, use_legacy_dataset)\u001b[0m\n\u001b[1;32m   1369\u001b[0m                 infer_dictionary=True)\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m         self._dataset = ds.dataset(path_or_paths, filesystem=filesystem,\n\u001b[0m\u001b[1;32m   1372\u001b[0m                                    \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparquet_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                                    \u001b[0mpartitioning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36mdataset\u001b[0;34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_filesystem_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_is_path_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFileInfo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36m_filesystem_dataset\u001b[0;34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0mfactory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileSystemDatasetFactory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths_or_selector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.DatasetFactory.finish\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/hf_file_system.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, length)\u001b[0m\n\u001b[1;32m   1014\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, length)\u001b[0m\n\u001b[1;32m   2081\u001b[0m             \u001b[0;31m# don't even bother calling fetch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2083\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m         logger.debug(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/fsspec/caching.py\u001b[0m in \u001b[0;36m_fetch\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_requested_bytes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# new block replaces old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/hf_file_system.py\u001b[0m in \u001b[0;36m_fetch_range\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m    975\u001b[0m         )\n\u001b[1;32m    976\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHF_HUB_DOWNLOAD_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m         \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;31m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;31m# as well (request id and/or server error message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHfHubHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://us.gcp.cdn.hf.co/xet-bridge-us/688396b205d1d6f23ea2db87/a2ee09c5cdb6feaa352311ab9e29183c7db352bf6b02539c8b36b2f63fef62f2?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pull_request.parquet%3B+filename%3D%22pull_request.parquet%22%3B&Expires=1764812658&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY0ODEyNjU4fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjg4Mzk2YjIwNWQxZDZmMjNlYTJkYjg3L2EyZWUwOWM1Y2RiNmZlYWEzNTIzMTFhYjllMjkxODNjN2RiMzUyYmY2YjAyNTM5YzhiMzZiMmY2M2ZlZjYyZjJcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=t3Ot17q9UhNsFr-KKdepa~eoNzo7HFwc0I1sWPLZuMPj2WVw4mExEhnmUf9YH~ZuZ4q3GtTfbI7riy7Db~VRKvu4sN9cAQf4cWCO6B9Xpg3xiiKxsllstM9fJ3yHGtHOmwsPIsOIU0LibBQkF0yWUkkaVyg1rbR8ouQHK~xXWAWLApw2LjYvU6mutcSRfkedomyec8xakIn3pyraiTsgABFOotMkUKGhr~zVZJReUG0y3OIC6b3iFGl4GfN4D9vpsctpO-69wx4TddgSQ74JW0I76CtOw~vlyD9UZlr43nLNNP49jgVhFfWctNQX7pmGvsHMgz6mrP7N-ctbaNKeyg__&Key-Pair-Id=KJLH8B0YWU4Y8M"]}],"source":["# How do time-to-first-review and time-to-merge differ between PRs with vs. without SAR patterns?\n","# -- How do these metrics vary by agent?\n","# -- How do they compare against non-SAR PRs?\n","# Compare individual agent times for SAR vs non-SAR\n","\n","print('Starting script.')\n","pd.set_option('display.max_rows', None)\n","pull_request_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pull_request.parquet\")\n","comments_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pr_comments.parquet\")\n","pr_task_type_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pr_task_type.parquet\")\n","print('Finished querying parquets.')\n","print(len(pull_request_df))\n","pull_request_df.rename(columns={'id': 'pr_id'}, inplace=True)"]},{"cell_type":"code","source":["# need body from pr_comments\n","combined_df = pull_request_df.merge(\n","    comments_df[['id', 'body']].add_prefix('comment_'),\n","    how='left',\n","    left_on='pr_id',\n","    right_on='comment_id',\n","    suffixes=('', '_task')\n",")\n","combined_df.drop(columns=['comment_id'])\n","\n","# only look at refactor\n","combined_df = combined_df.merge(\n","    pr_task_type_df[['id', 'type']],\n","    how='left',\n","    left_on='pr_id',\n","    right_on='id'\n",")\n","combined_df.rename(columns={'type': 'pr_type'}, inplace=True)\n","combined_df = combined_df.loc[combined_df['pr_type'].str.contains('refactor', na=False)].copy()\n","\n","print(combined_df['pr_id'].nunique())\n","\n","print(f\"Length of combined_df: {len(combined_df)}\")"],"metadata":{"id":"LdmIACeXiQfb","executionInfo":{"status":"aborted","timestamp":1764807367251,"user_tz":600,"elapsed":7869,"user":{"displayName":"Carol Wong","userId":"15667668278021680660"}}},"id":"LdmIACeXiQfb","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"e32461e2-245f-463a-a16d-4be032d3e6c3","metadata":{"id":"e32461e2-245f-463a-a16d-4be032d3e6c3","executionInfo":{"status":"aborted","timestamp":1764807367254,"user_tz":600,"elapsed":7872,"user":{"displayName":"Carol Wong","userId":"15667668278021680660"}}},"outputs":[],"source":["print('Beginning regex searches.')\n","\n","def to_regex_pattern(word):\n","    return re.escape(word).replace(r'\\*', '.*')\n","\n","bug_patterns = re.compile('|'.join(to_regex_pattern(w) for w in bug_words), re.IGNORECASE)\n","internal_patterns = re.compile('|'.join(to_regex_pattern(w) for w in internal_words), re.IGNORECASE)\n","external_patterns = re.compile('|'.join(to_regex_pattern(w) for w in external_words), re.IGNORECASE)\n","functional_patterns = re.compile('|'.join(to_regex_pattern(w) for w in functional_words), re.IGNORECASE)\n","smell_patterns = re.compile('|'.join(to_regex_pattern(w) for w in smell_words), re.IGNORECASE)\n","\n","all_patterns = re.compile(\n","    '|'.join(to_regex_pattern(w) for w in (bug_words + internal_words + external_words + functional_words + smell_words)),\n","    re.IGNORECASE\n",")\n","\n","print('Finished assembling regex patterns.')\n"]},{"cell_type":"code","execution_count":null,"id":"dc27efd0-d3b0-4461-835a-b3a051c55a06","metadata":{"id":"dc27efd0-d3b0-4461-835a-b3a051c55a06","executionInfo":{"status":"aborted","timestamp":1764807367257,"user_tz":600,"elapsed":1,"user":{"displayName":"Carol Wong","userId":"15667668278021680660"}}},"outputs":[],"source":["\n","print('Searching for sar patterns.')\n","# search for any pattern\n","combined_df['is_sar'] = (\n","    combined_df['body'].str.contains(all_patterns, na=False) |\n","    combined_df['comment_body'].str.contains(all_patterns, na=False) |\n","    combined_df['title'].str.contains(all_patterns, na=False)\n",")\n","print('Finished searching any pattern.')\n","\n","# search for specific category of pattern (bug, internal, external, functional, smell)\n","combined_df['bug'] = (\n","    combined_df['body'].str.contains(bug_patterns, na=False) |\n","    combined_df['comment_body'].str.contains(bug_patterns, na=False) |\n","    combined_df['title'].str.contains(bug_patterns, na=False)\n",")\n","print('Finished searching bug patterns.')\n","combined_df['internal'] = (\n","    combined_df['body'].str.contains(internal_patterns, na=False) |\n","    combined_df['comment_body'].str.contains(internal_patterns, na=False) |\n","    combined_df['title'].str.contains(internal_patterns, na=False)\n",")\n","print('Finished searching internal patterns.')\n","combined_df['external'] = (\n","    combined_df['body'].str.contains(external_patterns, na=False) |\n","    combined_df['comment_body'].str.contains(external_patterns, na=False) |\n","    combined_df['title'].str.contains(external_patterns, na=False)\n",")\n","print('Finished searching external patterns.')\n","combined_df['functional'] = (\n","    combined_df['body'].str.contains(functional_patterns, na=False) |\n","    combined_df['comment_body'].str.contains(functional_patterns, na=False) |\n","    combined_df['title'].str.contains(functional_patterns, na=False)\n",")\n","print('Finished searching functional patterns.')\n","combined_df['smell'] = (\n","    combined_df['body'].str.contains(smell_patterns, na=False) |\n","    combined_df['comment_body'].str.contains(smell_patterns, na=False) |\n","    combined_df['title'].str.contains(smell_patterns, na=False)\n",")\n","print('Finished searching smell patterns.')\n","\n","# search any category pattern in specific locations in the PR\n","combined_df['sar_in_pr_title'] = combined_df['title'].str.contains(all_patterns, na=False)\n","print('Finished searching for sar in title.')\n","combined_df['sar_in_pr_body'] = combined_df['body'].str.contains(all_patterns, na=False)\n","print('Finished searching for sar in body.')\n","combined_df['sar_in_pr_comment'] = combined_df['comment_body'].str.contains(all_patterns, na=False)\n","print('Finished searching for sar in comment.')\n","\n","# add column for merge time in DAYS instead of seconds\n","combined_df['merge_time'] = (pd.to_datetime(combined_df['merged_at']) - pd.to_datetime(combined_df['created_at'])).dt.total_seconds() / 86400"]},{"cell_type":"code","execution_count":null,"id":"beff5e75-a1a5-4160-bb65-5dfe11231d1e","metadata":{"id":"beff5e75-a1a5-4160-bb65-5dfe11231d1e","executionInfo":{"status":"aborted","timestamp":1764807367258,"user_tz":600,"elapsed":7874,"user":{"displayName":"Carol Wong","userId":"15667668278021680660"}}},"outputs":[],"source":["\n","unique_prs = combined_df.drop_duplicates(subset=['pr_id'])\n","\n","total_requests = (\n","    unique_prs\n","    .groupby(['agent', 'is_sar'])\n","    .size()\n","    # ** issue with my python LSP, not a problem at runtime **\n","    .reset_index(name='total_requests') # type: ignore\n",")\n","\n","agents = unique_prs['agent'].unique()\n","sar_flags = [True, False]\n","all_groups = pd.MultiIndex.from_product([agents, sar_flags], names=['agent', 'is_sar'])\n","\n","total_merged = (\n","    unique_prs[unique_prs['merged_at'].notna()]\n","    .groupby(['agent', 'is_sar'])['merge_time']\n","    .size()\n","    .reindex(all_groups, fill_value=0)\n","    .reset_index(name='total_merged') # type: ignore\n",")\n","\n","# find average of both sar and non_sar, and drop unmerged PRs\n","average_merged = (\n","    unique_prs[unique_prs['merged_at'].notna()]\n","    .groupby(['agent', 'is_sar'])['merge_time']\n","    .mean()\n","    .round(2)\n","    .reindex(all_groups, fill_value='n/a')\n","    .reset_index(name='average_merge_time(days)') # type: ignore\n",")\n","\n","sar_categories = (\n","    unique_prs\n","    .groupby(['agent', 'is_sar'])\n","    [['bug', 'internal', 'external', 'functional', 'smell']]\n","    .sum()\n","    .reset_index()\n",")\n","\n","sar_locations = (\n","    unique_prs\n","    .groupby(['agent', 'is_sar'])\n","    [['sar_in_pr_title', 'sar_in_pr_body', 'sar_in_pr_comment']]\n","    .sum()\n","    .reset_index()\n",")\n","\n","\n","summary = (\n","    total_requests\n","    .merge(total_merged, on=['agent', 'is_sar'], how='left')\n","    .merge(average_merged, on=['agent', 'is_sar'], how='left')\n","    .merge(sar_categories, on=['agent', 'is_sar'], how='left')\n","    .merge(sar_locations, on=['agent', 'is_sar'], how='left')\n",")\n","summary['merge_rate(%)'] = ((summary['total_merged'] / summary['total_requests']).round(2) * 100).astype(int)"]},{"cell_type":"code","source":["combined_df"],"metadata":{"collapsed":true,"id":"xHOfmz7V2nUK","executionInfo":{"status":"aborted","timestamp":1764807367259,"user_tz":600,"elapsed":7874,"user":{"displayName":"Carol Wong","userId":"15667668278021680660"}}},"id":"xHOfmz7V2nUK","execution_count":null,"outputs":[]},{"cell_type":"code","source":["summary"],"metadata":{"id":"DzcMBgx1iwHw","executionInfo":{"status":"aborted","timestamp":1764807367293,"user_tz":600,"elapsed":4,"user":{"displayName":"Carol Wong","userId":"15667668278021680660"}}},"id":"DzcMBgx1iwHw","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testing\n"],"metadata":{"id":"nbt37YvBU70h"},"id":"nbt37YvBU70h"},{"cell_type":"markdown","source":["## Two-Sample test of SAR and non-SAR PRs"],"metadata":{"id":"x45ewpOhIMpL"},"id":"x45ewpOhIMpL"},{"cell_type":"code","source":["rq_testing = unique_prs[unique_prs['merged_at'].notna()][['agent', 'is_sar', 'merge_time']].copy()\n","\n","# Check normality assumption to see if can use ANOVA test\n","# Shapiro-Wilk test\n","for agent in rq_testing['agent'].unique():\n","    for sar in [True, False]:\n","        data = rq_testing[(rq_testing['agent'] == agent) &\n","                          (rq_testing['is_sar'] == sar)]['merge_time']\n","        if len(data) >= 3:  # Need at least 3 samples\n","            stat, p = stats.shapiro(data)\n","            print(f\"  {agent} (SAR={sar}): W={stat:.4f}, p={p:.4f}\")\n","\n","# Levene's test\n","print(\"\\nLevene's test for homogeneity of variance:\")\n","groups = [group['merge_time'].values for name, group in\n","          rq_testing.groupby(['agent', 'is_sar'])]\n","stat, p = stats.levene(*groups)\n","print(f\"  Statistic={stat:.4f}, p={p:.4f}\")"],"metadata":{"id":"ExM8z0OQY_qL","executionInfo":{"status":"aborted","timestamp":1764807367295,"user_tz":600,"elapsed":4,"user":{"displayName":"Carol Wong","userId":"15667668278021680660"}}},"id":"ExM8z0OQY_qL","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Normality Assumptions:\n","- All Shapiro-Wilk p-values are less than 0.05 and Levene's p is less than 0.05, so normality and homogeneity assumptions are violated!!!\n","Use Kruskal-Wallis test instead"],"metadata":{"id":"yoMACbuIZUhn"},"id":"yoMACbuIZUhn"},{"cell_type":"code","source":["rq_testing['agent_sar'] = rq_testing['agent'] + '_' + rq_testing['is_sar'].astype(str)\n","groups_kw = [group['merge_time'].values for name, group in\n","             rq_testing.groupby('agent_sar')]\n","stat, p = kruskal(*groups_kw)\n","print(f\"Kruskal-Wallis H-statistic: {stat:.4f}, p-value: {p:.4f}\")"],"metadata":{"id":"b6DS73VxZJVc","executionInfo":{"status":"aborted","timestamp":1764807367300,"user_tz":600,"elapsed":8,"user":{"displayName":"Carol Wong","userId":"15667668278021680660"}}},"id":"b6DS73VxZJVc","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Kruskal-Wallis H: 558.7417 and p < 0.05 means there is significant differences across the agent-SAR combos"],"metadata":{"id":"wYC8oiXEZr8z"},"id":"wYC8oiXEZr8z"},{"cell_type":"code","source":["agent_results = []\n","\n","for agent in rq_testing['agent'].unique():\n","    print(f\"\\n{agent}\")\n","    print(\"-\" * 60)\n","\n","    agent_data = rq_testing[rq_testing['agent'] == agent]\n","    sar_data = agent_data[agent_data['is_sar'] == True]['merge_time']\n","    non_sar_data = agent_data[agent_data['is_sar'] == False]['merge_time']\n","\n","    n_sar = len(sar_data)\n","    n_non_sar = len(non_sar_data)\n","\n","    print(f\"  SAR PRs: n={n_sar}, mean={sar_data.mean():.4f}, median={sar_data.median():.4f}\")\n","    print(f\"  Non-SAR PRs: n={n_non_sar}, mean={non_sar_data.mean():.4f}, median={non_sar_data.median():.4f}\")\n","\n","    if n_sar >= 3 and n_non_sar >= 3:\n","        # Use Mann-Whitney U (non-parametric)\n","        stat, p_val = mannwhitneyu(sar_data, non_sar_data, alternative='two-sided')\n","        test_used = \"Mann-Whitney U test\"\n","\n","        # Calculate effect size (Cohen's d)\n","        pooled_std = np.sqrt(((n_sar-1)*sar_data.std()**2 +\n","                              (n_non_sar-1)*non_sar_data.std()**2) /\n","                             (n_sar + n_non_sar - 2))\n","        cohens_d = (sar_data.mean() - non_sar_data.mean()) / pooled_std\n","\n","        print(f\"  statistic={stat:.4f}, p-value={p_val:.4f}\")\n","        print(f\"  Cohen's d (effect size): {cohens_d:.4f}\")\n","\n","        agent_results.append({\n","            'agent': agent,\n","            'n_sar': n_sar,\n","            'n_non_sar': n_non_sar,\n","            'mean_sar': sar_data.mean(),\n","            'mean_non_sar': non_sar_data.mean(),\n","            'median_sar': sar_data.median(),\n","            'median_non_sar': non_sar_data.median(),\n","            'test': test_used,\n","            'p_value': p_val,\n","            'cohens_d': cohens_d,\n","            'significant': p_val < 0.05\n","        })\n","    else:\n","        print(f\"  Insufficient data for statistical testing (need n>=3 for both groups)\")\n","\n","results_df = pd.DataFrame(agent_results)\n","if len(results_df) > 0:\n","    print(results_df.to_string(index=False))"],"metadata":{"id":"rU0eWb4OZmNC","executionInfo":{"status":"aborted","timestamp":1764807367302,"user_tz":600,"elapsed":7,"user":{"displayName":"Carol Wong","userId":"15667668278021680660"}}},"id":"rU0eWb4OZmNC","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- Only OpenAI-Codex had significant results, as the p-value was below 0.05\n","  - SAR PRs merge faster than non-SAR PRs\n","  - The mean for a SAR is 0.24 days while the mean for a non-SAR was 0.45 days\n","  - Median for SAR: 0.002 days (which is about 3 minutes), median of non-SAR: 0.001 days (about 1.4 minutes)\n","  - SAR patterns have slightly faster merges\n","  - Cohen's D = 0.07 which means it is a very small effect though\n","\n","- Other agents did not have significant results (P > 0.05), but Copilot's SAR PRs tended to be slower. Claude also couldn't be tested as there were no merged SAR PRs in the dataset. All PRs that had SAR patterns were not merged, so no merge time\n","\n","# Threats to Validity\n","- Failed normality: The medians are much lower, meaning data is right-skewed with outliers\n","- Very large sample size imbalance for all agents\n","- All Cohen's d values are very small, suggesting that any differences are not very meaningful :(\n"],"metadata":{"id":"LzCmg82MaL4R"},"id":"LzCmg82MaL4R"},{"cell_type":"markdown","source":["# Results\n","- Time-to-merge does not differ meaningfully between PRs with and without SAR patterns overall (p = 1.000).\n","- Significant variation exists across agents (p < 0.001), but the agent-SAR interaction is not significant (p = 0.221).\n","- Only OpenAI_Codex shows a statistically significant difference (p = 0.006), where SAR PRs merge slightly faster than non-SAR PRs (median: 0.002 vs 0.001 days). However, this difference is not practically meaningful (Cohen's d = -0.07)."],"metadata":{"id":"_zAsu63abpiF"},"id":"_zAsu63abpiF"},{"cell_type":"code","source":["fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n","\n","# 1. Box plot by agent and SAR\n","ax1 = axes[0, 0]\n","rq_testing.boxplot(column='merge_time', by=['agent', 'is_sar'], ax=ax1)\n","ax1.set_title('Merge Time by Agent and SAR Pattern')\n","ax1.set_xlabel('Agent and SAR Pattern')\n","ax1.set_ylabel('Merge Time (days)')\n","plt.sca(ax1)\n","plt.xticks(rotation=45, ha='right')\n","\n","# 2. Violin plot\n","ax2 = axes[0, 1]\n","sns.violinplot(data=rq_testing, x='agent', y='merge_time', hue='is_sar',\n","               split=True, ax=ax2)\n","ax2.set_title('Distribution of Merge Times')\n","ax2.set_ylabel('Merge Time (days)')\n","ax2.legend(title='Has SAR Pattern')\n","\n","# 3. Mean comparison with error bars\n","ax3 = axes[1, 0]\n","means = rq_testing.groupby(['agent', 'is_sar'])['merge_time'].mean().unstack()\n","errors = rq_testing.groupby(['agent', 'is_sar'])['merge_time'].sem().unstack()\n","means.plot(kind='bar', yerr=errors, ax=ax3, capsize=4)\n","ax3.set_title('Mean Merge Time with Standard Error')\n","ax3.set_ylabel('Merge Time (days)')\n","ax3.set_xlabel('Agent')\n","ax3.legend(title='Has SAR Pattern', labels=['No SAR', 'Has SAR'])\n","plt.sca(ax3)\n","plt.xticks(rotation=45, ha='right')\n","\n","# 4. Count of PRs\n","ax4 = axes[1, 1]\n","counts = pd.crosstab(rq_testing['agent'], rq_testing['is_sar'])\n","counts.plot(kind='bar', stacked=True, ax=ax4)\n","ax4.set_title('Number of PRs by Agent and SAR Pattern')\n","ax4.set_ylabel('Count')\n","ax4.set_xlabel('Agent')\n","ax4.legend(title='Has SAR Pattern', labels=['No SAR', 'Has SAR'])\n","plt.sca(ax4)\n","plt.xticks(rotation=45, ha='right')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"1hfHN6xNbq-z","executionInfo":{"status":"aborted","timestamp":1764807367303,"user_tz":600,"elapsed":2,"user":{"displayName":"Carol Wong","userId":"15667668278021680660"}}},"id":"1hfHN6xNbq-z","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"39jm9oapcS0q","executionInfo":{"status":"aborted","timestamp":1764807367305,"user_tz":600,"elapsed":0,"user":{"displayName":"Carol Wong","userId":"15667668278021680660"}}},"id":"39jm9oapcS0q","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1969A0wmJyg9er_YkhjkBOlMxaaBenO-O","timestamp":1764807003103},{"file_id":"1tGURw4F94J5RGRuB2nbWcpbWM654d7IS","timestamp":1764465496482}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}